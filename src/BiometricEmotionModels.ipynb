{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab83164-b2db-4d7b-9d4a-8b4c63876feb",
   "metadata": {},
   "source": [
    "# Detecting Stress/Emotion Signals from Biometric Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9012ae-59dd-418d-96be-20801a763afc",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89cb5a32-e7f8-492a-9b5d-06537076674a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7cd6d-24e7-4b48-9aa7-f6a8598f0198",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b8e9e1-9f8e-4a21-8173-549117facc48",
   "metadata": {},
   "source": [
    "The WESAD dataset is a multimodal dataset for wearable stress and affect detection, collected from 15 subjects using two devices: a chest-worn RespiBAN and a wrist-worn Empatica E4. It includes synchronized physiological signals such as EDA, ECG, EMG, respiration, temperature, and acceleration, sampled at high resolution. Each subject underwent conditions like baseline, stress, and amusement, with corresponding labels provided in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e65e4a-8922-4ba1-889e-75e446251ce7",
   "metadata": {},
   "source": [
    "### Loading Signals and Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508b2bb-3866-43c0-8c71-ecb6b6f40e4a",
   "metadata": {},
   "source": [
    "#### Downsampling, windowing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a42cf3a-1db8-4428-a156-a5a46ac30f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLING_RATE_ORIG = 700\n",
    "SAMPLING_RATE_TARGET = 4\n",
    "WINDOW_SIZE_SEC = 15\n",
    "STRIDE_SEC = 5\n",
    "\n",
    "# Maps canonical names to actual keys in the dataset\n",
    "SIGNAL_MAP = {\n",
    "    'EDA': {'chest': 'EDA',   'wrist': 'EDA'},\n",
    "    'TEMP': {'chest': 'Temp', 'wrist': 'TEMP'},\n",
    "    'RESP': {'chest': 'Resp', 'wrist': None},   # Not available on wrist\n",
    "    'ECG': {'chest': 'ECG',   'wrist': None},   # Not available on wrist\n",
    "    'ACC': {'chest': 'ACC',   'wrist': 'ACC'},\n",
    "    'EMG': {'chest': 'EMG',   'wrist': None},\n",
    "    'BVP': {'chest': None,    'wrist': 'BVP'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "addf57f2-1d26-4f4e-b4f2-2295e7e4fb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_downsample(subject_path, signals, device='chest'):\n",
    "    with open(subject_path, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "    label = data['label']\n",
    "    scale = SAMPLING_RATE_TARGET / SAMPLING_RATE_ORIG\n",
    "    new_len = int(len(label) * scale)\n",
    "\n",
    "    signal_list = []\n",
    "\n",
    "    for sig in signals:\n",
    "        sig_key = SIGNAL_MAP[sig]\n",
    "        parts = []\n",
    "\n",
    "        for part in ['chest', 'wrist']:\n",
    "            if device in [part, 'both'] and sig_key[part]:\n",
    "                source = data['signal'][part][sig_key[part]]\n",
    "                if source.ndim == 1:\n",
    "                    source = source[:, np.newaxis]\n",
    "                s_down = resample(source, new_len, axis=0)\n",
    "                parts.append(s_down)\n",
    "\n",
    "        if parts:\n",
    "            signal_list.append(np.concatenate(parts, axis=1))\n",
    "\n",
    "    all_signals = np.concatenate(signal_list, axis=1)\n",
    "    labels = resample(label.astype(float), new_len).round().astype(int)\n",
    "    return all_signals, labels\n",
    "\n",
    "def normalize(data):\n",
    "    return StandardScaler().fit_transform(data)\n",
    "\n",
    "def create_windows(X, y, window_size=WINDOW_SIZE_SEC * SAMPLING_RATE_TARGET, stride=STRIDE_SEC * SAMPLING_RATE_TARGET):\n",
    "    windows, labels = [], []\n",
    "    for i in range(0, len(X) - window_size, stride):\n",
    "        win_x = X[i:i + window_size]\n",
    "        win_y = y[i:i + window_size]\n",
    "        if np.any(win_y == 0):\n",
    "            continue\n",
    "        majority_label = np.bincount(win_y).argmax()\n",
    "        windows.append(win_x)\n",
    "        labels.append(majority_label)\n",
    "    return np.array(windows), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6bc1bd-c43f-4c47-83c9-5743343a4964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PANAS_ITEMS = [\n",
    "    'Active', 'Distressed', 'Interested', 'Inspired', 'Annoyed', 'Strong', 'Guilty',\n",
    "    'Scared', 'Hostile', 'Excited', 'Proud', 'Irritable', 'Enthusiastic', 'Ashamed',\n",
    "    'Alert', 'Nervous', 'Determined', 'Attentive', 'Jittery', 'Afraid', 'Stressed',\n",
    "    'Frustrated', 'Happy', 'Angry', 'Irritated', 'Sad'\n",
    "]\n",
    "\n",
    "TARGET_PANAS = ['Stressed', 'Angry', 'Happy', 'Sad', 'Inspired', 'Excited', 'Nervous']  # you can modify this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df3006b-8886-4726-9ed5-a562cd213d50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_panas_scores(quest_path):\n",
    "    condition_scores = []\n",
    "\n",
    "    with open(quest_path, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=';')\n",
    "        rows = [r for r in reader if r and r[0].startswith('# PANAS')]\n",
    "\n",
    "    for row in rows:\n",
    "        try:\n",
    "            # Clean and parse only non-empty fields\n",
    "            scores = [int(val) for val in row[1:] if val.strip().isdigit()]\n",
    "            if len(scores) < len(PANAS_ITEMS):\n",
    "                continue\n",
    "            condition_scores.append(dict(zip(PANAS_ITEMS, scores)))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse PANAS in {quest_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return condition_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee98013-802c-40c3-a9a7-b4783d2d9bbe",
   "metadata": {},
   "source": [
    "#### Loading to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0827ab4-5bf4-406d-922a-5f88fa5d1fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_wesad_dataset(root_path, selected_signals=('EDA', 'TEMP', 'RESP', 'ECG', 'ACC'), device='chest'):\n",
    "    all_x, all_y_cls, all_y_reg, all_subject_ids = [], [], [], []\n",
    "\n",
    "    for subject_dir in sorted(os.listdir(root_path)):\n",
    "\n",
    "        if not subject_dir.startswith(\"S\"):\n",
    "            continue\n",
    "\n",
    "        pkl_path = os.path.join(root_path, subject_dir, f\"{subject_dir}.pkl\")\n",
    "        quest_path = os.path.join(root_path, subject_dir, f\"{subject_dir}_quest.csv\")\n",
    "\n",
    "        if not os.path.exists(pkl_path) or not os.path.exists(quest_path):\n",
    "            print(f\"Skipping {subject_dir}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            X, y = load_and_downsample(pkl_path, selected_signals, device)\n",
    "            X = normalize(X)\n",
    "            win_x, win_y = create_windows(X, y)\n",
    "\n",
    "            # === Load PANAS Scores ===\n",
    "            panas_per_condition = extract_panas_scores(quest_path)\n",
    "            y_reg = []\n",
    "\n",
    "            for label in win_y:\n",
    "                condition_idx = label - 1  # 1=Base, 2=Stress, ...\n",
    "                if condition_idx >= len(panas_per_condition):\n",
    "                    y_reg.append([0.0] * len(TARGET_PANAS))  # fallback\n",
    "                    continue\n",
    "\n",
    "                score_vec = [panas_per_condition[condition_idx][key] for key in TARGET_PANAS]\n",
    "                y_reg.append(score_vec)\n",
    "\n",
    "            all_x.append(win_x)\n",
    "            all_y_cls.append(win_y)\n",
    "            all_y_reg.append(np.array(y_reg))\n",
    "            \n",
    "            subject_ids = [subject_dir] * len(win_x)  # same ID for all windows from this subject\n",
    "            all_subject_ids.append(np.array(subject_ids))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {subject_dir}: {e}\")\n",
    "    \n",
    "    return (\n",
    "        np.concatenate(all_x),\n",
    "        np.concatenate(all_y_cls),\n",
    "        np.concatenate(all_y_reg),\n",
    "        np.concatenate(all_subject_ids)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d3d1b-8af0-4287-a28f-3ff33d29705f",
   "metadata": {},
   "source": [
    "#### Define class for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb27a13-603a-4430-9172-d2abd3cc5f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WESADDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0381b16-d7cb-4940-8162-163bd48fca7b",
   "metadata": {},
   "source": [
    "#### Load and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8cfdf8-d98e-4a92-9828-fcb4ceec53c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: (9120, 60, 12)\n",
      "Classification labels: (9120,)\n",
      "PANAS regression targets: (9120, 7)\n"
     ]
    }
   ],
   "source": [
    "X, y_cls, y_reg, subject_ids = load_wesad_dataset(\n",
    "    root_path=\"../data/WESAD\",\n",
    "    selected_signals=('EDA', 'TEMP', 'RESP', 'ECG', 'ACC'),\n",
    "    device='both'\n",
    ")\n",
    "\n",
    "print(\"Features:\", X.shape)\n",
    "print(\"Classification labels:\", y_cls.shape)\n",
    "print(\"PANAS regression targets:\", y_reg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7508c762-180e-491d-9e27-412154adf9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save for later regression task\n",
    "X_reg = X\n",
    "subject_ids_reg = subject_ids\n",
    "\n",
    "# Define mask\n",
    "valid_mask = (y_cls >= 1) & (y_cls <= 4)\n",
    "\n",
    "# Apply masking\n",
    "X = X[valid_mask]\n",
    "y_cls = y_cls[valid_mask] - 1\n",
    "\n",
    "subject_ids = np.array(subject_ids)[valid_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088f698-d7c5-4c48-b775-c30de30d40d9",
   "metadata": {},
   "source": [
    "## Modeling - Condition Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d34fd2-a9a7-4b1e-9d57-e72c3a4f47c8",
   "metadata": {},
   "source": [
    "### Split and Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d07d7fd-ace4-41bc-8ab8-db6b18be4af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unique subjects\n",
    "unique_subjects = sorted(set(subject_ids))\n",
    "train_subjects, val_subjects = train_test_split(unique_subjects, test_size=0.2, random_state=42)\n",
    "\n",
    "# Subject-level masks\n",
    "train_mask = np.isin(subject_ids, train_subjects)\n",
    "val_mask = np.isin(subject_ids, val_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7813beb0-396c-4876-b588-5bc6fe1c0c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_cls_train = X[train_mask], y_cls[train_mask]\n",
    "X_val,   y_cls_val   = X[val_mask],   y_cls[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dac4ed16-7829-45ab-8818-29460d003290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WESADClassificationDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = WESADClassificationDataset(X_train, y_cls_train)\n",
    "val_ds   = WESADClassificationDataset(X_val, y_cls_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af54fde-7490-479e-aaf3-bc27a129e8bf",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35e9cfa0-816e-4671-a6ae-aeac57d9ddb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNEmotionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=12, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, 12, 60)\n",
    "        x = self.net(x)\n",
    "        x = x.squeeze(-1)       # (B, 256)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34acd7d0-45ff-41aa-8025-15261afd24a5",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e16fef4-618b-4b5f-a730-c4bbe528cf41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels:\", np.unique(y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "821ad29a-a15f-4c48-a6de-37d3e01796f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNNEmotionClassifier(input_dim=12, num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e821497f-9cec-4e99-9c40-25508066094c",
   "metadata": {},
   "source": [
    "### Set Up Training / Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8a55b77-2be3-45a0-a3ef-0f141488afa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e3dfad2-ee75-4cda-93a3-72f17994a177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f0a92-58a5-4896-9ac7-5d65f582522b",
   "metadata": {},
   "source": [
    "### Run Training / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13037593-b527-41b3-ab56-1ae4bc410dca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.3137 | Acc: 0.8947 | Val Loss: 0.8289 | Acc: 0.7955\n",
      "Epoch 02 | Train Loss: 0.0646 | Acc: 0.9826 | Val Loss: 1.0672 | Acc: 0.7994\n",
      "Epoch 03 | Train Loss: 0.0310 | Acc: 0.9922 | Val Loss: 1.0234 | Acc: 0.8040\n",
      "Epoch 04 | Train Loss: 0.0226 | Acc: 0.9942 | Val Loss: 0.9121 | Acc: 0.7994\n",
      "Epoch 05 | Train Loss: 0.0162 | Acc: 0.9953 | Val Loss: 0.8207 | Acc: 0.8466\n",
      "Epoch 06 | Train Loss: 0.0124 | Acc: 0.9963 | Val Loss: 1.2622 | Acc: 0.8074\n",
      "Epoch 07 | Train Loss: 0.0063 | Acc: 0.9990 | Val Loss: 1.1858 | Acc: 0.7869\n",
      "Epoch 08 | Train Loss: 0.0051 | Acc: 0.9984 | Val Loss: 1.1133 | Acc: 0.8091\n",
      "Epoch 09 | Train Loss: 0.0023 | Acc: 0.9994 | Val Loss: 1.1484 | Acc: 0.8102\n",
      "Epoch 10 | Train Loss: 0.0071 | Acc: 0.9981 | Val Loss: 1.7754 | Acc: 0.7824\n",
      "Epoch 11 | Train Loss: 0.0104 | Acc: 0.9979 | Val Loss: 1.3348 | Acc: 0.8239\n",
      "Epoch 12 | Train Loss: 0.0088 | Acc: 0.9979 | Val Loss: 1.0663 | Acc: 0.8551\n",
      "Epoch 13 | Train Loss: 0.0012 | Acc: 0.9999 | Val Loss: 1.0458 | Acc: 0.8222\n",
      "Epoch 14 | Train Loss: 0.0010 | Acc: 0.9997 | Val Loss: 1.0227 | Acc: 0.8375\n",
      "Epoch 15 | Train Loss: 0.0004 | Acc: 1.0000 | Val Loss: 0.9959 | Acc: 0.8545\n",
      "Epoch 16 | Train Loss: 0.0004 | Acc: 1.0000 | Val Loss: 1.0080 | Acc: 0.8426\n",
      "Epoch 17 | Train Loss: 0.0003 | Acc: 1.0000 | Val Loss: 1.0062 | Acc: 0.8483\n",
      "Epoch 18 | Train Loss: 0.0002 | Acc: 1.0000 | Val Loss: 1.0124 | Acc: 0.8483\n",
      "Epoch 19 | Train Loss: 0.0002 | Acc: 1.0000 | Val Loss: 0.9898 | Acc: 0.8392\n",
      "Epoch 20 | Train Loss: 0.0003 | Acc: 1.0000 | Val Loss: 0.9960 | Acc: 0.8540\n",
      "Epoch 21 | Train Loss: 0.0004 | Acc: 1.0000 | Val Loss: 1.1496 | Acc: 0.8170\n",
      "Epoch 22 | Train Loss: 0.0005 | Acc: 1.0000 | Val Loss: 1.0372 | Acc: 0.8591\n",
      "Epoch 23 | Train Loss: 0.0025 | Acc: 0.9990 | Val Loss: 1.0438 | Acc: 0.8273\n",
      "Epoch 24 | Train Loss: 0.0313 | Acc: 0.9920 | Val Loss: 1.3900 | Acc: 0.8006\n",
      "Epoch 25 | Train Loss: 0.0128 | Acc: 0.9966 | Val Loss: 1.6482 | Acc: 0.7750\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 26):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb4c7daf-2dd6-47ee-b019-f379ae67486f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"cnn_emotion_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92da5a3-19c2-4bcd-8712-898fe0640b28",
   "metadata": {},
   "source": [
    "## Modeling - Emotion Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efbcb4e-ec1d-4a50-bc2c-e4b11551fdd7",
   "metadata": {},
   "source": [
    "### Split and Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3696017-7d66-477f-8056-49b43688dd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WESADRegressionDataset(Dataset):\n",
    "    def __init__(self, X, y_reg):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y_reg, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe02b2e8-6835-4485-8915-3f382c2dcf06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Include subject ids\n",
    "subject_ids = np.array(subject_ids_reg)\n",
    "\n",
    "# Normalize score\n",
    "y_reg = (y_reg - 1) / 4.0\n",
    "\n",
    "train_mask = np.isin(subject_ids, train_subjects)\n",
    "val_mask   = np.isin(subject_ids, val_subjects)\n",
    "\n",
    "X_train, y_reg_train = X_reg[train_mask], y_reg[train_mask]\n",
    "X_val,   y_reg_val   = X_reg[val_mask],   y_reg[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dc3cd6c-b7a0-4e25-a342-27da2cad31c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = WESADRegressionDataset(X_train, y_reg_train)\n",
    "val_ds   = WESADRegressionDataset(X_val,   y_reg_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18bf6df-a443-4738-a09d-f961240a304c",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87d68c10-8e9b-4efb-a462-574924b01252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PANASRegressor(nn.Module):\n",
    "    def __init__(self, input_dim=12, output_dim=7):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.regressor = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)     # (B, 12, 60)\n",
    "        x = self.encoder(x)        # (B, 256, 1)\n",
    "        x = x.squeeze(-1)          # (B, 256)\n",
    "        return self.regressor(x)   # (B, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e2bafdc-b9b6-4409-865d-a2af0cadfd67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PANASRegressor(input_dim=12, output_dim=7).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c24677-5b31-42c9-8dfd-97c0e0d6e924",
   "metadata": {},
   "source": [
    "### Set Up Training / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82251fc3-39ec-4707-bb28-76810d4633a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_regression(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed654332-2e16-49df-91f6-a0ec16f27a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_regression(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "\n",
    "        loss = criterion(pred, y)\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "\n",
    "        all_preds.append(pred.cpu().numpy())\n",
    "        all_targets.append(y.cpu().numpy())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(all_targets, all_preds)\n",
    "    mae = mean_absolute_error(all_targets, all_preds)\n",
    "\n",
    "    # Pearson correlation per dimension\n",
    "    pearsons = [pearsonr(all_preds[:, i], all_targets[:, i])[0] for i in range(all_targets.shape[1])]\n",
    "\n",
    "    return total_loss / len(loader.dataset), mse, mae, pearsons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a73696-51ef-42b0-8206-49306b4c94d6",
   "metadata": {},
   "source": [
    "### Run Training / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "451a3460-85e2-4a2d-aa40-550b1f0b1bac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.0325 | Val Loss: 0.0645 | MSE: 0.0645 | MAE: 0.1547 | Pearson r: ['0.803', '0.874', '0.553', '0.790', '0.500', '0.662', '0.820']\n",
      "Epoch 02 | Train Loss: 0.0077 | Val Loss: 0.0745 | MSE: 0.0745 | MAE: 0.1654 | Pearson r: ['0.741', '0.822', '0.621', '0.762', '0.650', '0.646', '0.779']\n",
      "Epoch 03 | Train Loss: 0.0038 | Val Loss: 0.0845 | MSE: 0.0845 | MAE: 0.1807 | Pearson r: ['0.721', '0.801', '0.585', '0.739', '0.634', '0.608', '0.761']\n",
      "Epoch 04 | Train Loss: 0.0025 | Val Loss: 0.0749 | MSE: 0.0749 | MAE: 0.1678 | Pearson r: ['0.761', '0.801', '0.604', '0.765', '0.679', '0.647', '0.801']\n",
      "Epoch 05 | Train Loss: 0.0018 | Val Loss: 0.0722 | MSE: 0.0722 | MAE: 0.1607 | Pearson r: ['0.750', '0.773', '0.601', '0.764', '0.700', '0.631', '0.797']\n",
      "Epoch 06 | Train Loss: 0.0014 | Val Loss: 0.0718 | MSE: 0.0718 | MAE: 0.1641 | Pearson r: ['0.797', '0.773', '0.582', '0.776', '0.666', '0.660', '0.821']\n",
      "Epoch 07 | Train Loss: 0.0010 | Val Loss: 0.0723 | MSE: 0.0723 | MAE: 0.1627 | Pearson r: ['0.759', '0.772', '0.580', '0.769', '0.672', '0.627', '0.801']\n",
      "Epoch 08 | Train Loss: 0.0008 | Val Loss: 0.0696 | MSE: 0.0696 | MAE: 0.1575 | Pearson r: ['0.760', '0.785', '0.620', '0.765', '0.698', '0.631', '0.802']\n",
      "Epoch 09 | Train Loss: 0.0006 | Val Loss: 0.0759 | MSE: 0.0759 | MAE: 0.1666 | Pearson r: ['0.746', '0.735', '0.579', '0.756', '0.676', '0.599', '0.781']\n",
      "Epoch 10 | Train Loss: 0.0005 | Val Loss: 0.0711 | MSE: 0.0711 | MAE: 0.1599 | Pearson r: ['0.753', '0.727', '0.628', '0.763', '0.684', '0.633', '0.793']\n",
      "Epoch 11 | Train Loss: 0.0005 | Val Loss: 0.0767 | MSE: 0.0767 | MAE: 0.1649 | Pearson r: ['0.767', '0.759', '0.572', '0.768', '0.667', '0.627', '0.800']\n",
      "Epoch 12 | Train Loss: 0.0003 | Val Loss: 0.0761 | MSE: 0.0761 | MAE: 0.1619 | Pearson r: ['0.786', '0.778', '0.589', '0.779', '0.676', '0.640', '0.813']\n",
      "Epoch 13 | Train Loss: 0.0004 | Val Loss: 0.0720 | MSE: 0.0720 | MAE: 0.1584 | Pearson r: ['0.763', '0.766', '0.610', '0.774', '0.678', '0.634', '0.797']\n",
      "Epoch 14 | Train Loss: 0.0003 | Val Loss: 0.0680 | MSE: 0.0680 | MAE: 0.1502 | Pearson r: ['0.750', '0.760', '0.626', '0.781', '0.696', '0.658', '0.795']\n",
      "Epoch 15 | Train Loss: 0.0008 | Val Loss: 0.0739 | MSE: 0.0739 | MAE: 0.1559 | Pearson r: ['0.799', '0.817', '0.595', '0.798', '0.694', '0.666', '0.827']\n",
      "Epoch 16 | Train Loss: 0.0003 | Val Loss: 0.0704 | MSE: 0.0704 | MAE: 0.1516 | Pearson r: ['0.799', '0.830', '0.596', '0.800', '0.681', '0.666', '0.825']\n",
      "Epoch 17 | Train Loss: 0.0003 | Val Loss: 0.0675 | MSE: 0.0675 | MAE: 0.1490 | Pearson r: ['0.792', '0.825', '0.601', '0.808', '0.666', '0.677', '0.827']\n",
      "Epoch 18 | Train Loss: 0.0002 | Val Loss: 0.0638 | MSE: 0.0638 | MAE: 0.1442 | Pearson r: ['0.812', '0.861', '0.611', '0.813', '0.675', '0.690', '0.839']\n",
      "Epoch 19 | Train Loss: 0.0002 | Val Loss: 0.0681 | MSE: 0.0681 | MAE: 0.1479 | Pearson r: ['0.780', '0.779', '0.633', '0.798', '0.698', '0.665', '0.811']\n",
      "Epoch 20 | Train Loss: 0.0002 | Val Loss: 0.0695 | MSE: 0.0695 | MAE: 0.1509 | Pearson r: ['0.788', '0.825', '0.613', '0.795', '0.686', '0.666', '0.819']\n",
      "Epoch 21 | Train Loss: 0.0002 | Val Loss: 0.0659 | MSE: 0.0659 | MAE: 0.1457 | Pearson r: ['0.794', '0.800', '0.638', '0.803', '0.681', '0.669', '0.821']\n",
      "Epoch 22 | Train Loss: 0.0002 | Val Loss: 0.0875 | MSE: 0.0875 | MAE: 0.1704 | Pearson r: ['0.732', '0.728', '0.596', '0.754', '0.694', '0.599', '0.759']\n",
      "Epoch 23 | Train Loss: 0.0009 | Val Loss: 0.0700 | MSE: 0.0700 | MAE: 0.1516 | Pearson r: ['0.788', '0.825', '0.578', '0.796', '0.664', '0.648', '0.819']\n",
      "Epoch 24 | Train Loss: 0.0002 | Val Loss: 0.0665 | MSE: 0.0665 | MAE: 0.1441 | Pearson r: ['0.774', '0.809', '0.618', '0.809', '0.687', '0.683', '0.814']\n",
      "Epoch 25 | Train Loss: 0.0002 | Val Loss: 0.0688 | MSE: 0.0688 | MAE: 0.1472 | Pearson r: ['0.778', '0.805', '0.600', '0.797', '0.683', '0.664', '0.809']\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 26):\n",
    "    train_loss = train_regression(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_mse, val_mae, val_corr = evaluate_regression(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | MSE: {val_mse:.4f} | MAE: {val_mae:.4f} | \"\n",
    "          f\"Pearson r: {['%.3f' % r for r in val_corr]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41f64d43-5b56-404d-93f9-6784e116cd46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Emotion Pearson Correlation (sorted):\n",
      "Nervous    | r = 0.809\n",
      "Angry      | r = 0.805\n",
      "Sad        | r = 0.797\n",
      "Stressed   | r = 0.778\n",
      "Inspired   | r = 0.683\n",
      "Excited    | r = 0.664\n",
      "Happy      | r = 0.600\n"
     ]
    }
   ],
   "source": [
    "# Pair names with r values\n",
    "emotion_r = list(zip(TARGET_PANAS, val_corr))\n",
    "\n",
    "# Sort descending by correlation\n",
    "emotion_r_sorted = sorted(emotion_r, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Per-Emotion Pearson Correlation (sorted):\")\n",
    "for name, r in emotion_r_sorted:\n",
    "    print(f\"{name:10s} | r = {r:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07378e06-c62a-42dd-8265-6738f052e80b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"cnn_emotion_regressor.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
